# -*- coding: utf-8 -*-
"""Final Model Comparisons.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YVhH5EO4bpcJ6yeTWoE6uKSfyR1FRMk0

## Step 1: Import Dependencies and Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
!pip install pandas_profiling
import numpy as np    # linear algebra
import pandas as pd    # Data processing, Input & Output load

import xgboost as xgb
from sklearn.ensemble import GradientBoostingClassifier    # GBM algorithm


from xgboost.sklearn import XGBClassifier    # Extreme Gradient Boosting

import joblib  #Joblib is a set of tools to provide lightweight pipelining in Python (Avoid computing twice the same thing)
from sklearn.model_selection import train_test_split as tts
from sklearn.model_selection import cross_val_score, GridSearchCV
                                    # GridSearchCV - Implements a “fit” and a “score” method
                                    # train_test_split - Split arrays or matrices into random train and test subsets
                                    # cross_val_score - Evaluate a score by cross-validation
from sklearn.linear_model import LogisticRegression


from sklearn.metrics import mean_squared_error
from sklearn.metrics import f1_score, precision_score, accuracy_score, roc_auc_score, recall_score, roc_curve
from sklearn.metrics import make_scorer, confusion_matrix, classification_report   # Differnt metrics to evaluate the model
import pandas_profiling as pp    # simple and fast exploratory data analysis of a Pandas Dataframe

import warnings    # To avoid warning messages in the code run
warnings.filterwarnings('ignore')

"""## Step 2: Import Dataset"""

import pandas as pd
diabetes = pd.read_csv('data.csv')
diabetes
data = pd.read_csv('data2.csv')

"""## Step 3: Applying the Label Encoder"""

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

for i in diabetes.columns[1:] :
    diabetes[i] = le.fit_transform(diabetes[i])

diabetes

"""## Step 4: Spliting Independent and dependent features

a.) Independent Variables
"""

x=diabetes.iloc[:,:-1].values
x

"""b.) Dependent Variables"""

y=diabetes.iloc[:,-1].values
y

"""## Step 5: Transform Data using Standard Scaler"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x=sc.fit_transform(x)
x

"""## Step 6: Save the transform data using joblib"""

import joblib
joblib.dump(sc,'diabetes_respondent_transform')

"""## Step 7: Splitting the dataset into 80% training data and 20% testing data"""

X_train, X_test, y_train, y_test = tts(x, y, test_size = 0.3, random_state = 100)

print('Train Shape: ', X_train.shape)
print('Test Shape: ', X_test.shape)

"""## Step 8: Construct Model using Gradient Boosting"""

model_parameters = {'n_estimators': [10, 50, 100, 200, 500, 750, 1000], 'max_depth': [3, 5, 10],
                    'min_samples_leaf': [np.random.randint(1,10)], 'max_features': [None, 'sqrt', 'log2']}

model = GradientBoostingClassifier(random_state = 10)
gscv_GBM = GridSearchCV(estimator = model,
                        param_grid = model_parameters,
                        cv = 5,
                        verbose = 1,
                        n_jobs = -1,
                        scoring = 'roc_auc')

gscv_GBM.fit(X_train, y_train)

"""### a.) Refitting the data"""

gradient_booster_model = GradientBoostingClassifier(**gscv_GBM.best_params_)
gradient_booster_model.fit(X_train, y_train)

"""### b.) Displaying model prediction and classification report"""

train_pred = gradient_booster_model.predict(X_train)
test_pred = gradient_booster_model.predict(X_test)

print('Classification report for train data is : \n',
      classification_report(y_train, train_pred))
print('Classification report for test data is : \n',
      classification_report(y_test, test_pred))

"""### c.) Making predictions for test data by testing the model"""

y_pred = gradient_booster_model.predict(X_test)
predictions = [round(value) for value in y_pred]
predictions

"""### d.) Checking the prediction accuracy for test data of the model"""

gbm_accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (gbm_accuracy * 100.0))

"""### e.) Model Evaluation Metrics"""

from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred)))
print('Precision Score : ' + str(precision_score(y_test, y_pred)))
print('Recall Score : ' + str(recall_score(y_test, y_pred)))
print('F1 Score : ' + str(f1_score(y_test, y_pred)))

"""### f.) Confusion Matrix"""

from sklearn.metrics import confusion_matrix
cf_matrix = confusion_matrix(y_test,y_pred)
print(cf_matrix)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import seaborn as sns
sns.heatmap(cf_matrix, annot=True)

labels = ["True Negative","False Positive","False Negative","True Positive"]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cf_matrix, annot=labels, fmt="", cmap='Blues')

group_names = ["True Negative","False Positive","False Negative","True Positive"]
group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cf_matrix, annot=labels, fmt="", cmap='Blues')

"""### g.) Saving the Gradient Boosting Model"""

joblib.dump(gradient_booster_model, 'diabetes_model')

"""## **Construct Model using Logistic Regression**




"""

from sklearn.linear_model import LogisticRegression

# instantiate the model
logreg =  LogisticRegression(solver='liblinear')
# fit the model with data
logreg.fit(X_train,y_train)
# predicting
y_pred=logreg.predict(X_test)
y_pred

"""# Check accuracy of Logistic Regression Model"""

log_accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (log_accuracy * 100.0))

"""#Logistic Regression Model Evaluation Metrics"""

print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred)))
print('Precision Score : ' + str(precision_score(y_test, y_pred)))
print('Recall Score : ' + str(recall_score(y_test, y_pred)))
print('F1 Score : ' + str(f1_score(y_test, y_pred)))

"""# Model Evaluation using Confusion Matrix"""

log_matrix = confusion_matrix(y_test,y_pred)
print(log_matrix)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import seaborn as sns
sns.heatmap(log_matrix, annot=True)

group_names = ["True Negative","False Positive","False Negative","True Positive"]
group_counts = ["{0:0.0f}".format(value) for value in
                log_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     log_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(log_matrix, annot=labels, fmt="", cmap='Greens')

"""### Construct Model using Random Forest Classifier"""

# importing random forest classifier from assemble module
from sklearn.ensemble import RandomForestClassifier
# Create a Random forest Classifier
RF = RandomForestClassifier(n_estimators = 100)
# Train the model using the training sets
random_forest = RF.fit(X_train, y_train)

# performing predictions on the test dataset
y_pred = random_forest.predict(X_test)
y_pred

"""## Check accuracy of Random Forest Model"""

log_accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (log_accuracy * 100.0))

"""#Random Forest Model Evaluation Metrics"""

print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred)))
print('Precision Score : ' + str(precision_score(y_test, y_pred)))
print('Recall Score : ' + str(recall_score(y_test, y_pred)))
print('F1 Score : ' + str(f1_score(y_test, y_pred)))

"""## Random Forest Confusion Matrix"""

rf_matrix = confusion_matrix(y_test,y_pred)
print(log_matrix)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import seaborn as sns
sns.heatmap(rf_matrix, annot=True)

group_names = ["True Negative","False Positive","False Negative","True Positive"]
group_counts = ["{0:0.0f}".format(value) for value in
                rf_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     rf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(rf_matrix, annot=labels, fmt="", cmap='Reds')

"""### **Construct Model using Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

# Create Decision Tree classifer object
dt = DecisionTreeClassifier()
# Train Decision Tree Classifer
dt = dt.fit(X_train,y_train)
#Predict the response for test dataset
y_pred = dt.predict(X_test)
y_pred

"""## Check accuracy of Decision Tree Model"""

dt_accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (dt_accuracy * 100.0))

"""#Decision Model Evaluation Metrics"""

print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred)))
print('Precision Score : ' + str(precision_score(y_test, y_pred)))
print('Recall Score : ' + str(recall_score(y_test, y_pred)))
print('F1 Score : ' + str(f1_score(y_test, y_pred)))

"""## Decison Tree Confusiion Matrix"""

dt_matrix = confusion_matrix(y_test,y_pred)
print(dt_matrix)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import seaborn as sns
sns.heatmap(dt_matrix, annot=True)

group_names = ["True Negative","False Positive","False Negative","True Positive"]
group_counts = ["{0:0.0f}".format(value) for value in
                dt_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     dt_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(dt_matrix, annot=labels, fmt="", cmap='Purples')

"""### **Naive Bayes**"""

#Import Gaussian Naive Bayes model
from sklearn.naive_bayes import GaussianNB
#Create a Gaussian Classifier
NB = GaussianNB()
# Train Decision Tree Classifer
NB = NB.fit(X_train,y_train)
#Predict the response for test dataset
y_pred = NB.predict(X_test)
y_pred

"""# Naive Bayes Accuracy"""

NB_accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (NB_accuracy * 100.0))

"""# Naive Bayes Model Evaluation Metrics"""

print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred)))
print('Precision Score : ' + str(precision_score(y_test, y_pred)))
print('Recall Score : ' + str(recall_score(y_test, y_pred)))
print('F1 Score : ' + str(f1_score(y_test, y_pred)))

"""# Naive Bayes Confusion MAtrix"""

NB_matrix = confusion_matrix(y_test,y_pred)
print(NB_matrix)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import seaborn as sns
sns.heatmap(NB_matrix, annot=True)

group_names = ["True Negative","False Positive","False Negative","True Positive"]
group_counts = ["{0:0.0f}".format(value) for value in
                NB_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     NB_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(NB_matrix, annot=labels, fmt="", cmap='Oranges')

"""# **Support Vector Machine**"""

#Import svm model
from sklearn import svm
#Create a svm Classifier
SVM = svm.SVC(kernel='linear',probability=True) # Linear Kernel
#Train the model using the training sets
SVM.fit(X_train, y_train)
#Predict the response for test dataset
y_pred = SVM.predict(X_test)
y_pred

"""# SVM Accuracy"""

SVM_accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (SVM_accuracy * 100.0))

"""# SVM model evaluation metrics"""

print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred)))
print('Precision Score : ' + str(precision_score(y_test, y_pred)))
print('Recall Score : ' + str(recall_score(y_test, y_pred)))
print('F1 Score : ' + str(f1_score(y_test, y_pred)))

"""# SVM Confusion Matrix"""

SVM_matrix = confusion_matrix(y_test,y_pred)
print(SVM_matrix)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import seaborn as sns
sns.heatmap(SVM_matrix, annot=True)

group_names = ["True Negative","False Positive","False Negative","True Positive"]
group_counts = ["{0:0.0f}".format(value) for value in
                SVM_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     SVM_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(SVM_matrix, annot=labels, fmt="", cmap='Accent')

"""# **PRECISSION RECALL CURVE**"""

from sklearn.metrics import precision_recall_curve

y_true1 = y_test # true labels of your data (e.g., y_test)
y_score1 =gradient_booster_model.predict_proba(X_test)[:, 1] # predicted scores (probabilities) of your model
y_score2 =logreg.predict_proba(X_test)[:, 1]
y_score3 =random_forest.predict_proba(X_test)[:, 1]
y_score4 =dt.predict_proba(X_test)[:, 1]
y_score5 =NB.predict_proba(X_test)[:, 1]
y_score6 =SVM.predict_proba(X_test)[:, 1]

precision1, recall1, thresholds1 = precision_recall_curve(y_true1, y_score1)
precision2, recall2, thresholds2 = precision_recall_curve(y_true1, y_score2)
precision3, recall3, thresholds3 = precision_recall_curve(y_true1, y_score3)
precision4, recall4, thresholds4 = precision_recall_curve(y_true1, y_score4)
precision5, recall5, thresholds5 = precision_recall_curve(y_true1, y_score5)
precision6, recall6, thresholds6 = precision_recall_curve(y_true1, y_score6)

import matplotlib.pyplot as plt

plt.plot(recall1, precision1, label='Gradient Boosting')
plt.plot(recall2, precision2, label='Logistic Regression')
plt.plot(recall3, precision3, label='Random Forest')
plt.plot(recall4, precision4, label='Decision Tree')
plt.plot(recall5, precision5, label='Naive Bayes')
plt.plot(recall6, precision6, label='SVM')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.legend()
# Set the tick marks on the x-axis to be at intervals of 0.1
plt.xticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])
plt.figure(figsize=(20, 18))
plt.show()

"""### FEATURE IMPORTANCE"""

import matplotlib.pyplot as plt

# Plot feature importances
importances = gradient_booster_model.feature_importances_
feat_names = diabetes.columns
indices = np.argsort(importances)[::-1]

fig, ax = plt.subplots()
ax.bar(range(X_train.shape[1]), importances[indices])
ax.set_xticks(range(X_train.shape[1]))
ax.set_xticklabels(feat_names[indices], rotation=90)
ax.set_title("Feature Importance")
plt.tight_layout()
plt.show()

"""## PARTIAL DEPENDENCE PLOT"""

!pip uninstall scikit-learn
!pip install scikit-learn==1.1.0

"""just change index to access features"""

# Create PDP for a single feature
from sklearn.inspection import plot_partial_dependence
from matplotlib import pyplot as plt
fig, ax = plt.subplots(figsize=(10,6))
plot_partial_dependence(gradient_booster_model, X_train, [0], feature_names=feat_names, ax=ax)
ax.set_xlabel(feat_names[0])
ax.set_ylabel("Partial Dependence")
ax.set_title("Partial Dependence Plot for {}".format(feat_names[0]))
plt.tight_layout()
plt.show()

"""## DECISION TREE

## **SHAP**
"""

!pip install shap
import shap

# load the explainer and get shap values
explainer = shap.TreeExplainer(gradient_booster_model)
shap_values = explainer.shap_values(X_train)

# create a summary plot
shap.summary_plot(shap_values, X_train, max_display=50, feature_names = diabetes.columns)

from sklearn.tree import export_graphviz
import graphviz

# get the first tree from the gradient boosting model
estimator = gradient_booster_model.estimators_[40,0]

# define the feature names
feature_names = data.columns

# export the decision tree to dot format
dot_data = export_graphviz(
    estimator,
    out_file=None,
    feature_names=feature_names,
    class_names=['Positive', 'Negative'], # replace with your own class names
    filled=True,
    rounded=True,
    special_characters=True
)

# modify the default graph attributes to scale the size of the tree
graph_attr = {'size': '10,10'}

# convert dot format to graph object
graph = graphviz.Source(dot_data)

# save the graph to your device
graph.render(filename='final_tree1', format='png')

# display the graph
graph

num_trees = gradient_booster_model.n_estimators_
num_trees